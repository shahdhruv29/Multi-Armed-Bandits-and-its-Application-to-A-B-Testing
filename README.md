# Multi-Armed Bandits and its Application to A/B Testing

In this repository we explore the topic of Multi Armed Bandits and A/B Testing using various sources and papers. 

> **Papers and Articles:** </br>
> 1. [Multi Armed Bandit vs. A/B Tests in E-commerce - Confidence Interval and Hypothesis Test Power Perspectives](https://dl.acm.org/doi/abs/10.1145/3534678.3539144)

> **Books** </br>
> 1. [Reinforcement Learning: An Introduction](http://incompleteideas.net/book/the-book-2nd.html) </br>
> 2. [Introduction To Multi-Armed Bandits](https://arxiv.org/abs/1904.07272)</br>
> 3. [Bandit Algorithms](https://tor-lattimore.com/downloads/book/book.pdf)</br>

> **Useful links:** </br>
> 1. [Sequential Decision Analytics](https://castle.princeton.edu/sda/) </br>
> 2. [MAB vs A/B Testing vs Thompson Sampling](https://www.linkedin.com/pulse/multi-armed-bandits-thompson-sampling-ab-testing-you-headlines-ronny/)

